# Gesture-Controlled-Drone-Simulation
A computer-vision-based drone simulation that allows users to control a virtual drone using hand gestures captured via webcam. The system integrates gesture recognition, physics simulation, HUD visualization, and flight data logging.
ğŸ“Œ Features
ğŸ¥ Real-time hand tracking using MediaPipe
âœ‹ Gesture-based flight commands:
Hover
Forward Thrust
Backward Thrust
Strafe Left
Landing
ğŸ“Š Tactical HUD showing:
Velocity
Altitude
Battery percentage
ğŸ”‹ Battery consumption model
ğŸ§­ World boundary & ground-level safety
ğŸ§¾ CSV flight data logging
ğŸ–¥ï¸ Dual-screen view (Camera + Simulation)
ğŸ§  Gesture Mapping
Gesture
Action
All fingers down
Landing
All fingers up
Hover
Two fingers up
Forward Thrust
One finger up
Backward Thrust
Three fingers up
Strafe Left
ğŸ› ï¸ Tech Stack
Python
OpenCV
MediaPipe
NumPy
â–¶ï¸ How to Run
Copy code
Bash
pip install opencv-python mediapipe numpy
python main.py
ğŸ“· Ensure your webcam is connected before running.
ğŸ“ Output
Real-time drone simulation window
Gesture-controlled navigation
Flight log saved as:
Copy code

comprehensive_flight_log.csv
ğŸ“ Educational Value
This project demonstrates:
Human-Computer Interaction (HCI)
Real-time Computer Vision
Physics-based simulation
State machines & telemetry systems
ğŸ‘¤ Author
Sakshi pagare
Artificial intelligence Student
